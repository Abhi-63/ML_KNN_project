{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: [96.89922480620154, 96.89922480620154, 95.34883720930233, 96.12403100775194, 98.44961240310077]\n",
      "Accuracy :  96.74418604651162 %\n"
     ]
    }
   ],
   "source": [
    "from random import seed\n",
    "from random import randrange\n",
    "from csv import reader\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt \n",
    "import time  \n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import classification_report\n",
    " \n",
    "\n",
    "\n",
    "\n",
    "#spliting the data into number_of_flods_data \n",
    "#by using the cross validation we encouter some better accuracy\n",
    "def split_cross_validation(data, no_flods):\n",
    "\tdata_split = list()\n",
    "\tdata_copy = list(data)\n",
    "\tsize = int(len(data) / no_flods)\n",
    "\tfor _ in range(no_flods):\n",
    "\t\ttemp = list()\n",
    "\t\twhile len(temp) < size:\n",
    "\t\t\tidx = randrange(len(data_copy))         #copy the random data to temp \n",
    "\t\t\ttemp.append(data_copy.pop(idx))\n",
    "\t\tdata_split.append(temp)\n",
    "\treturn data_split\n",
    " \n",
    "\n",
    "#finding the accuracy matrics\n",
    "def accu_matric(actual, predict):\n",
    "\tcrt = 0\n",
    "\tfor j in range(len(actual)):\n",
    "\t\tif actual[j] == predict[j]:         #if actual is equal to predict we increment into 1\n",
    "\t\t\tcrt =crt+1\n",
    "\treturn crt / float(len(actual)) * 100.0   #calculating the accuracy percentage\n",
    " \n",
    "\n",
    "#finding the k nearest neighbouring for train and test data\n",
    "def k_nearest_neigh(train, test, no_neigh):\n",
    "\tpredictions = list()\n",
    "\tfor i in test:\n",
    "\t\tneigh = get_KNN(train, i , no_neigh)       #getting the neighbour points w.r.t test data set\n",
    "\t\toutput_val = [i[-1] for i in neigh]         #getting values of the neigh\n",
    "\t\tpredict = max(set(output_val), key=output_val.count) #optaining the maximum output_values\n",
    " \n",
    "\t\tpredictions.append(predict)                #appending it to the prediction list\n",
    "\treturn(predictions)\n",
    "\n",
    "\n",
    "def dataset_min_max(data):\n",
    "\tmin_max = list()\n",
    "\tfor j in range(len(data)):\n",
    "\t\tcol_val = [j[i] for j in data]  #iterating each column val wrt row\n",
    "\t\tval_min = min(col_val)        #min value among the column\n",
    "\t\tval_max = max(col_val)        #max value among the column\n",
    "\t\tmin_max.append([val_min, val_max])\n",
    "\treturn min_max\n",
    "\n",
    "def e_d(x1 , x2):          #euclidean distance\n",
    "    distance = 0.0\n",
    "    for i in range(len(x1)-1):\n",
    "        distance =distance+(x1[i] - x2[i])**2\n",
    "    return sqrt(distance)\n",
    "\n",
    "def manhattan_dist(x1 , x2):     #manhattan distance\n",
    "    distance = 0.0\n",
    "    for i in range(len(x1)-1):\n",
    "        distance =distance+abs(x1[i] - x2[i])\n",
    "    return distance\n",
    "\n",
    "def get_KNN(train, test_a, no_neigh):\n",
    "    distances = list()\n",
    "    l=list()\n",
    "  #  print(len(test_a))\n",
    "   # print(len(train))\n",
    "    for train_k in train:\n",
    "        #print(train_k)\n",
    "        #l.append(1)\n",
    "        dist = e_d(test_a , train_k)\n",
    "        #dist = manhattan_dist(test_a , train_k)\n",
    "        distances.append((train_k, dist))         #appending the train_data and euclidean distance to the  list\n",
    "    #print(len(l))\n",
    "    distances.sort(key=lambda tup: tup[1])       #sorting the data into ascending order w.r.t euclidean distance\n",
    "    neigh = list()\n",
    "    for i in range(no_neigh):             #finding the neigh w.r.t euclidean distance\n",
    "        neigh.append(distances[i][0])\n",
    "    \n",
    "    return neigh\n",
    "\n",
    "#finding the normalize of the data\n",
    "def normalization(data, min_max):\n",
    "    for j in data:\n",
    "        for i in range(len(j)):                 #finding the normalize of each row\n",
    "            j[i] = (j[i] - min_max[i][0]) / (min_max[i][1] - min_max[i][0])\n",
    "\n",
    "\n",
    "def algo(data, algorithm, no_flods, *args):\n",
    "    flods_data = split_cross_validation(data, no_flods)  #spliting the data into flods_data\n",
    "    score = list()\n",
    "    predicted = list()\n",
    "    act = list()\n",
    "    for part in flods_data:\n",
    "        train_data = list(flods_data)              #spliting the data into train and test dataset \n",
    "        train_data.remove(part)\n",
    "        train_data = sum(train_data, [])      \n",
    "        test_data = list()\n",
    "        for i in part:\n",
    "            r_copy = list(i)\n",
    "            test_data.append(r_copy)\n",
    "            r_copy[-1] = None\n",
    "        predict = algorithm(train_data, test_data, *args)   #predicting the neigh\n",
    "        predicted.append(predict)\n",
    "        #print(len(train_data))\n",
    "        #print(len(test_data))\n",
    "        actual = [i[-1] for i in part]\n",
    "        #act.append(actual)\n",
    "        accuracy = accu_matric(actual, predict)\n",
    "        score.append(accuracy)\n",
    "    \n",
    "    \n",
    "    #results = confusion_matrix(act, predicted) \n",
    "    #print('Confusion Matrix :')\n",
    "    #print(results) \n",
    "    #print('Report : ')\n",
    "    #print(classification_report(act, predicted))\n",
    "\n",
    " \n",
    "\n",
    "    return score\n",
    " \n",
    "def avg(lst):\n",
    "    return sum(lst)/len(lst)\n",
    "\n",
    "\n",
    "\n",
    "#program starts from here\n",
    "\n",
    "file_name = 'cat1.csv'                  #csv file \n",
    "data=list()\n",
    "with open( file_name ,'r') as file:           #loading the csv file(readable)\n",
    "#reading of csv file\n",
    "    csv_read = reader(file)\n",
    "    for k in csv_read:                          #iterating the csv file w.r.t each row\n",
    "        if k:\n",
    "            data.append(k)                    #appending the data into the list(in readable format)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "#print(len(data[0]))  #row length\n",
    "#print(len(data))     #coulum length\n",
    "\n",
    "#converting the plain text into the math  form\n",
    "\n",
    "for k in range(len(data[0])-1): \n",
    "    for l in data:\n",
    "        l[k] = float(l[k].strip())              #converting into the float from\n",
    "    #print(data)\n",
    "        \n",
    "    #converting in the math form\n",
    "r=len(data[0])-1\n",
    "\n",
    "class_val = [i[r] for i in data]\n",
    "unique = set(class_val)                      #eliminate the repeated values\n",
    "temp = dict()                                   #initializing the dictionary type\n",
    "for i, value in enumerate(unique):\n",
    "    temp[value] = i\n",
    "for j in data:\n",
    "    j[r] = temp[j[r]]\n",
    "    #print(data)\n",
    "    \n",
    "    \n",
    "no_flods = 5  #divid the dataset into no_flods\n",
    "no_neigh = 10 #K value\n",
    "\n",
    "\n",
    "#print(data[0])\n",
    "\n",
    "min_max = dataset_min_max(data)\n",
    "#print(min_max)\n",
    "#print(len(min_max))\n",
    "normalization(data,min_max)\n",
    "#print(data[0])\n",
    "#print(len(normalize))\n",
    "\n",
    "#t = list()\n",
    "#a = list()\n",
    "#j = 0\n",
    "\n",
    "#k = [5,10,15,20,25,30]\n",
    "#for i in k:\n",
    "st=time.time()\n",
    "scores = algo(data , k_nearest_neigh , no_flods , no_neigh)   #algorith to find the  knn\n",
    "en = time.time()\n",
    "print('Scores: %s'% scores)\n",
    "#print(\"time\", en-st)\n",
    "#t.append(en-st)\n",
    "acc = avg(scores)\n",
    "print('Accuracy : ',acc,'%')\n",
    "#a.append(acc)\n",
    "\n",
    "#plt.plot(k,a)\n",
    "#plt.title('Predict highest accuracy for \"k value\"')\n",
    "#plt.xlabel('K value')\n",
    "#plt.ylabel('Accuracy')\n",
    "\n",
    "#plt.plot(k,t)\n",
    "#plt.title('k value vs time using \"Manhattan distance\"')\n",
    "#plt.xlabel('k value')\n",
    "#plt.ylabel('Time')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
